= Fake rest-json app used for demo
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
ifndef::env-github[]
:imagesdir: ./img
endif::[]
:toc:
:toc-placement!:

This app offers a simple REST API for the purpose of the performance tests that are demonstrated in this project. This was build based on Quarkus rest-json-quickstart project.
If you want to learn more about Quarkus, please visit its website: https://quarkus.io/ .

Different response times can be simulated [TO DO]. The following parameters are configurable through a configMap and related to the processing of a single message.

* load in fraction of CPU cores available (capped to 1)
* duration in milliseconds
* load deviation
* duration deviation

The distribution is normal/Gaussian:

  Random.nextGaussian() x processing.duration.deviation + processing.duration

If the processing duration is set to 50 a deviation of 10 means that 70% of values will fall between duration +/- 10, in other words between 40 and 60 milliseconds.
Choosing a value of 0 means no deviation and the duration or load is always the same.

Failure injection may be added with a future version.

== Build

My preferred way of manipulating container and container images is with podman and buildah on my laptop powered by linux. That said I acknowledge that a lot of people do not have this good fortune or even the opportunity to run docker locally. https://github.com/GoogleContainerTools/jib[Jib] allows to work around that and what we will be using here.
Quarkus offers a convenient way of adding the jib extension to the pom with:

 ./mvnw quarkus:add-extension -Dextensions="container-image-jib"

It is also possible to add files to the resulting image by placing them under src/main/jib with the complete path they will have on the container filesystem.

Once that's done the application and a runtime image can be built and pushed to your preferred registry, quay.io here, with a single command:

 ./mvnw clean package -Dquarkus.container-image.build=true -Dquarkus.container-image.push=true -Dquarkus.container-image.registry=quay.io -Dquarkus.container-image.group=fgiloux -Dquarkus.container-image.username=fgiloux -Dquarkus.container-image.password="XXXXXXXXXXXXXXXXXXXX" -Dquarkus.container-image.insecure=true

Alternatively it is possible to push the image directly to the registry embedded with an OpenShift cluster, CodeReady Container here:

 ./mvnw clean package -Dquarkus.container-image.build=true -Dquarkus.container-image.push=true -Dquarkus.container-image.registry=default-route-openshift-image-registry.apps-crc.testing -Dquarkus.container-image.group=test -Dquarkus.container-image.username=user -Dquarkus.container-image.password=XXXXXXXXXXXXXXXXXXXXXxxx -Dquarkus.container-image.insecure=true

* container-image.group matches a Kubernetes namespace.
* quarkus.container-image.password is the access token, either from a service account or from a user retrieved by $ oc whoami -t
* quarkus.container-image.insecure=true

Note: the user specified with container-image.username needed to have registry-editor role for the command to succeed. image-pusher was not enough and there is an open issue at the time of writing for addressing this. 

 $ oc adm policy add-cluster-role-to-user registry-editor developer

== Digression on security

*Controlling system calls*

As part of soak testing it is possible to create a custom seccomp profile for the application. This increases security of the platform by trimming down the number of system call types that can be done from the container. https://podman.io/blogs/2019/10/15/generate-seccomp-profiles.html[Here] are instructions on how podman and OCI hooks can be leveraged for the purpose.

Once a custom seccomp profile has been created (similar to the one available in this repository) it is possible to configure the container to make use of with podman:

 podman run --name fakeapp --security-opt seccomp=seccomp.json quay.io/fgiloux/rest-json-fakeapp:1.0-SNAPSHOT

For doing the same with OpenShift or Kubernetes with CRI-O the profile needs to be copied on the nodes and an annotation set on the pod or container:

 seccomp.security.alpha.kubernetes.io/pod: "localhost/seccomp.json"
 container.seccomp.security.alpha.kubernetes.io/<container_name>: "localhost/seccomp.json"

https://github.com/saschagrunert/seccomp-operator/blob/master/RFC.md[Further work] is being done that hopefully will allow to distribute specific seccomp profiles more easily through a ConfigMap or another mean.

*Controlling file access*

Besides system calls controlled by seccomp another aspect of security is SELinux policies. In most cases as here with this example you should be fine with the default security policy but if your container requires access to devices, files or ports on the host system it may need extra rights. Rather than running it as "privileged" it may be solved by creating a specific policy. An example I came across was a policy created for the use of NVidia GPU in OpenShift. https://github.com/containers/udica[Udica] is a convenient tool for the purpose.

*Controlling capabilities*

Capabilities inside a container are by default limited by the container runtime, for instance https://github.com/cri-o/cri-o/blob/release-1.19/internal/config/capabilities/capabilities.go#L14-L27[with cri-o]. Additional capabilities are dropped by the restricted scc in OpenShift: KILL, MKNOD (not allowed by default in cri-o), SETUID, SETGID. Security Context Constraints have been contributed to Kubernetes as PodSecurityPolicy, so that they can be used for the same goal. As application developer you are the best to know, which capabilities may be needed by your application and you can drop or add them as required.

== Deployment

Quarkus maven extension can generate object definitions that get stored in a list in target/kubernetes/kubernetes.yml
Therefore the following dependency needs to be added to the pom:

  <dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-kubernetes</artifactId>
  </dependency>

The following command will then get the file generated:

 $ ./mvnw clean package -Dquarkus.kubernetes.deploy=true -Dquarkus.container-image.registry=quay.io

Although very useful as a starting point I like to treat configuration as code and use a GitOps approach. In this respect I find better suited to have one file per object definition and to leverage https://github.com/kubernetes-sigs/kustomize[kustomize] for managing environment specifics. Tools like https://github.com/fluxcd/flux[Flux] or https://argoproj.github.io/argo-cd/[ArgoCD] can then be used for continuous delivery but this is another story. 

[TODO]

== Monitoring

With Quarkus it is straightforward to add MicroProfile metrics that are consumable by Prometheus. Therefore it is enough to add the follwoing dependency to the pom:

   <dependency>
      <groupId>io.quarkus</groupId>
      <artifactId>quarkus-smallrye-metrics</artifactId>
    </dependency>

JVM metrics get then exposed by default. With very simple annotations counters, gauges and timers get added for the REST services.

From the Prometheus side a serviceMonitor needs to get created to instruct Prometheus to scrap the application metrics.

   apiVersion: monitoring.coreos.com/v1
   kind: ServiceMonitor
   metadata:
     labels:
       app.kubernetes.io/name: quarkus-getting-started
     name: qgs-monitor
   spec:
     endpoints:
     - interval: 30s
       port: http
       scheme: http
     selector:
       matchLabels:
         app.kubernetes.io/name: "rest-json-fakeapp"

It is then possible to build graphs and dashboards similar to this one (and surely nicer ones) where you can visualize how your application react to load both in term of response time and resource consumption.

image::graph.png[]

== Certificates

The certificate extraction and keystore creation.... 
[TO DO]

[source,bash]
----
$ mkdir certs
$ ...
$ keytool -v -import -file certs/tls.crt -alias cacrt -keystore certs/app.jks
----

The next step is to create a secret containing the java keystore and the password to access it:

[source,bash]
----
$ oc create secret generic app-jks --from-literal=transport.trustStorePassword=xxxxxx --from-file=./certs/app.jks
----

The secret can then be mounted in the container by updating the deployment configuration with the following command. You won't need this step if you have used the deployment configuration definition file provided in the git repository.

 $ oc set volume dc/fakeapp --add --name=broker-jks -m /opt/broker-jks -t secret --secret-name=app-broker-jks

== Configuration externalisation

[TODO]
You may have noted that the openshift directory in the git repository also contains a configMap. This configMap is used for externalising environment dependent properties that are injected into the application through application.properties. Defaults can be defined in the property file provided with the application archive (jar). Only properties whose values should be overwritten can be specified in the ConfigMap.

 $ oc create configmap fakeapp-props --from-env-file=src/main/resources/application.properties

 application.properties is a streamlined version only including values that differ from the ones embedded in the jar.

Mounting the configMap

 $ oc set volume dc/fakeapp --add --name=app-properties -m /deployments/configuration -t configmap --configmap-name=fakeapp-props


Updating the deployment to make use of the new application.properties

 $ oc set env dc/fakeapp....................... 


